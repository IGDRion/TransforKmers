{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab215205-8946-416f-b1ba-dac3229d442d",
   "metadata": {},
   "source": [
    "Uses:\n",
    "- bedtools\n",
    "- gffread\n",
    "- seqtk\n",
    "- ushuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a5fcca-516d-4a9f-a41b-7662f11630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from gtf import GTF\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from transforkmers.fasta import Fasta\n",
    "from scripts.extract_regions import get_intervals\n",
    "\n",
    "SEQLEN = 1024\n",
    "RAWDIR = \"../data/01_raw/\"\n",
    "INTDIR = f\"../data/02_intermediate/{SEQLEN}/\"\n",
    "PRODIR = f\"../data/03_processed/{SEQLEN}/\"\n",
    "EXTREMITY = \"5prime\" # 3prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370a3719-2100-49ea-9717-7c9c5f57e655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can_Fam4.UU_Cfam_GSD_1.0.fa\n",
      "Can_Fam4.UU_Cfam_GSD_1.0.fa.fai\n",
      "Can_Fam4.UU_Cfam_GSD_1.0.gtf\n",
      "Homo_sapiens.GRCh38.101.gtf\n",
      "Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa\n",
      "Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.fai\n",
      "Mus_musculus.GRCm39.104.gtf\n",
      "Mus_musculus.GRCm39.dna_sm.primary_assembly.fa\n",
      "Mus_musculus.GRCm39.dna_sm.primary_assembly.fa.fai\n"
     ]
    }
   ],
   "source": [
    "!ls {RAWDIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce21bf0-5044-4ac1-bac7-91dd27acd7f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "First we associate each annotation (`gtf`) with its genome (`fa`) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beee33f5-ed72-4be2-925e-fb3c454b00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    ( RAWDIR + \"Can_Fam4.UU_Cfam_GSD_1.0.gtf\", RAWDIR + \"Can_Fam4.UU_Cfam_GSD_1.0.fa\" ),\n",
    "    ( RAWDIR + \"Mus_musculus.GRCm39.104.gtf\", RAWDIR + \"Mus_musculus.GRCm39.dna_sm.primary_assembly.fa\" ),\n",
    "    ( RAWDIR + \"Homo_sapiens.GRCh38.101.gtf\",  RAWDIR + \"Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa\" )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6fd9d2-161a-4221-a8f0-d0c0c893a02a",
   "metadata": {},
   "source": [
    "# Extract first exon position of GTFs\n",
    "\n",
    "Next, we iterate over GTFs, and extract only the first transcript of each lncRNA/mRNA gene with only one exon.\n",
    "Then, we use gffread to extract their nucleotid sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "811880df-e597-4f93-944a-04eaae8384a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XM_038588931 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589022 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589172 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589283 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589372 skipped: Start Coordinate detected that is < 0.\n",
      "XR_005387195 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589427 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589461 skipped: Start Coordinate detected that is < 0.\n",
      "XR_005387314 skipped: Start Coordinate detected that is < 0.\n",
      "XR_005387315 skipped: Start Coordinate detected that is < 0.\n",
      "XR_005387316 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589530 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589538 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589591 skipped: Start Coordinate detected that is < 0.\n",
      "XR_005387382 skipped: Start Coordinate detected that is < 0.\n",
      "XM_038589650 skipped: Start Coordinate detected that is < 0.\n",
      "XR_005387502 skipped: Start Coordinate detected that is < 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature (chrUn_JAAHUQ010000447v1:28826-29850) beyond the length of chrUn_JAAHUQ010000447v1 size (29740 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010000447v1:28825-29849) beyond the length of chrUn_JAAHUQ010000447v1 size (29740 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010000570v1:27205-28229) beyond the length of chrUn_JAAHUQ010000570v1 size (27726 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010000583v1:26931-27955) beyond the length of chrUn_JAAHUQ010000583v1 size (27445 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001124v1:108363-109387) beyond the length of chrUn_JAAHUQ010001124v1 size (109253 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001230v1:86319-87343) beyond the length of chrUn_JAAHUQ010001230v1 size (87233 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001563v1:60842-61866) beyond the length of chrUn_JAAHUQ010001563v1 size (61621 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001568v1:60894-61918) beyond the length of chrUn_JAAHUQ010001568v1 size (61673 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001575v1:60625-61649) beyond the length of chrUn_JAAHUQ010001575v1 size (61317 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001720v1:56241-57265) beyond the length of chrUn_JAAHUQ010001720v1 size (57090 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001862v1:51275-52299) beyond the length of chrUn_JAAHUQ010001862v1 size (51894 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001995v1:43429-44453) beyond the length of chrUn_JAAHUQ010001995v1 size (44099 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001995v1:43431-44455) beyond the length of chrUn_JAAHUQ010001995v1 size (44099 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010001995v1:43450-44474) beyond the length of chrUn_JAAHUQ010001995v1 size (44099 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002045v1:42337-43361) beyond the length of chrUn_JAAHUQ010002045v1 size (43123 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002046v1:42582-43606) beyond the length of chrUn_JAAHUQ010002046v1 size (43137 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002077v1:42001-43025) beyond the length of chrUn_JAAHUQ010002077v1 size (42588 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002097v1:41722-42746) beyond the length of chrUn_JAAHUQ010002097v1 size (42242 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002371v1:48158-49182) beyond the length of chrUn_JAAHUQ010002371v1 size (48954 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002378v1:36649-37673) beyond the length of chrUn_JAAHUQ010002378v1 size (37471 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002408v1:36113-37137) beyond the length of chrUn_JAAHUQ010002408v1 size (37072 bp).  Skipping.\n",
      "Feature (chrUn_JAAHUQ010002417v1:36285-37309) beyond the length of chrUn_JAAHUQ010002417v1 size (36798 bp).  Skipping.\n",
      "Feature (chrUn_MU018724v1:309928-310952) beyond the length of chrUn_MU018724v1 size (310765 bp).  Skipping.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(INTDIR, exist_ok=True)\n",
    "\n",
    "biotypes = set([\"lncRNA\", \"protein_coding\", \"processed_transcript\",\n",
    "                \"retained_intron\", \"antisense\", \"non_coding\", \"TEC\"])\n",
    "\n",
    "for gtf, fa in files:\n",
    "    sample = gtf.split(\"/\")[-1].split(\".\")[0]\n",
    "    mono_bed = f\"{INTDIR}/{sample}.{EXTREMITY}.bed\"\n",
    "    \n",
    "    with open(gtf) as fd:\n",
    "        transcripts = []\n",
    "        for gene in GTF.parse(fd):\n",
    "            exts = set()\n",
    "            \n",
    "            for transcript in gene.transcripts:\n",
    "                # Check biotype\n",
    "                if transcript[\"transcript_biotype\"] not in biotypes:\n",
    "                    continue\n",
    "                \n",
    "                # Extract good extremity based on strand and desired extremity\n",
    "                if (\n",
    "                    (EXTREMITY == \"3prime\" and transcript.strand == \"+\") \n",
    "                    or \n",
    "                    (EXTREMITY == \"5prime\" and transcript.strand == \"-\")\n",
    "                ):\n",
    "                        ext = transcript.end\n",
    "                elif (\n",
    "                    (EXTREMITY == \"3prime\" and transcript.strand == \"-\")\n",
    "                    or\n",
    "                    (EXTREMITY == \"5prime\" and transcript.strand == \"+\")\n",
    "                ):\n",
    "                        ext = transcript.start\n",
    "                \n",
    "                # Check if extremity not already seen in other isoforms\n",
    "                if ext not in exts:\n",
    "                    exts.add(ext)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                transcripts.append(transcript)\n",
    "        \n",
    "    intervals = get_intervals(transcripts, SEQLEN, int(EXTREMITY[0]))\n",
    "    \n",
    "    with open(mono_bed, \"w\") as wr:\n",
    "        for interval in intervals:\n",
    "            wr.write(\"\\t\".join(map(str, interval)) + \"\\n\")\n",
    "\n",
    "    !bedtools getfasta -name -fi {fa} -bed {mono_bed} | tr a-z A-Z > {INTDIR + sample}.{EXTREMITY}.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b998890-c104-482f-bac8-199fd9df64fb",
   "metadata": {},
   "source": [
    "At this step, we have, for each specie, a fasta file containing the sequences labeled `True`. We can combine the differents samples together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d252cbf8-36d2-457c-ba94-09fdd85a0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {INTDIR}/*.{EXTREMITY}.fa > {INTDIR}/species.{EXTREMITY}.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cffce831-0248-4636-9613-0db18caa914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398757\n"
     ]
    }
   ],
   "source": [
    "!grep -c \">\" {INTDIR}/species.{EXTREMITY}.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96a6d7c-0017-44db-b124-15fb53e584a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATED = \"/groups/dog/tderrien/matthias/validTSS/Can_Fam4.5prime_validCAGE1tpm_1rep.gtf\"\n",
    "!gffread {VALIDATED} -w - -g {FALSE_FA} | tr a-z A-Z > {INTDIR}/{PREFIX}.cage.5prime.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9ddeb-41f6-4ce3-8464-f8d6a7cc41ad",
   "metadata": {},
   "source": [
    "# Create false gene sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d39b490-9297-4ad6-b582-c7365f85de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dog\n",
    "#TRUE_FA = f\"{INTDIR}/Can_Fam4.5prime.fa\"\n",
    "#PREFIX = \"cf4\"\n",
    "#REF_GTF = RAWDIR + \"Can_Fam4.UU_Cfam_GSD_1.0.gtf\"\n",
    "#REF_FA = RAWDIR + \"Can_Fam4.UU_Cfam_GSD_1.0.fa\"\n",
    "#CHROM_URL = \"https://hgdownload.soe.ucsc.edu/goldenPath/canFam4/bigZips/canFam4.chrom.sizes\"\n",
    "#GAP_URL = \"https://genome.ucsc.edu/cgi-bin/hgTables?hgsid=1348135893_FTFAH4yg3MzSgyQwThJE0XIXxvZR&boolshad.hgta_printCustomTrackHeaders=0&hgta_ctName=tb_gap&hgta_ctDesc=table+browser+query+on+gap&hgta_ctVis=pack&hgta_ctUrl=&fbQual=whole&fbUpBases=200&fbDownBases=200&hgta_doGetBed=get+BED\"\n",
    "\n",
    "# Human\n",
    "TRUE_FA = f\"{INTDIR}/Homo_sapiens.5prime.fa\"\n",
    "PREFIX = \"hsa\"\n",
    "REF_GTF = RAWDIR + \"Homo_sapiens.GRCh38.101.gtf\"\n",
    "REF_FA = RAWDIR + \"Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa\"\n",
    "CHROM_URL=\"http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes\"\n",
    "GAP_URL=\"https://genome.ucsc.edu/cgi-bin/hgTables?hgsid=1299645359_OnnDUejIEZ3YloLAAPZTeauGP1Ra&boolshad.hgta_printCustomTrackHeaders=0&hgta_ctName=tb_gap&hgta_ctDesc=table+browser+query+on+gap&hgta_ctVis=pack&hgta_ctUrl=&fbQual=whole&fbUpBases=200&fbDownBases=200&hgta_doGetBed=get+BED\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49328989-1788-4052-a3c6-0c0732695862",
   "metadata": {},
   "source": [
    "## Shuffle true gene sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69e89e7-715a-405d-8698-d2502ba73587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with (\n",
    "    open(TRUE_FA) as fd, \n",
    "    open(f\"{INTDIR}/{PREFIX}.shuffled.species.{EXTREMITY}.fa\", \"w\") as wr, \n",
    "    open(f\"{INTDIR}/{PREFIX}.sequences_length.bed\", \"w\") as bed\n",
    "):\n",
    "    fa = Fasta(fd)\n",
    "    for i, seq in enumerate(fa):\n",
    "        if i%3 == 0: # Shuffle sequence\n",
    "            seq.id = f\"{seq.id}_shuffled\"\n",
    "            seq.seq = ''.join(random.sample(seq.seq, len(seq)))\n",
    "            wr.writelines(seq.write())\n",
    "        else: # Extract length for futur random picking sequence\n",
    "            seq.id = f\"{seq.id}_random\"\n",
    "            bed.write(f'1\\t0\\t{len(seq.seq)}\\t{seq.id}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc82bb-b37f-4595-8483-eaa41c4e5f39",
   "metadata": {},
   "source": [
    "## Pick random DNA sequences\n",
    "\n",
    "### Exclusion of unwanted regions\n",
    "\n",
    "#### Exclude gene positions\n",
    "\n",
    "First, we extract gene positions from reference transcriptome of Homo sapiens and store theme in `bed` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb32193-57c7-4ca9-997c-30e972311eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -P \"\\tgene\\t\" {REF_GTF} | cut -f1,4,5 > {INTDIR}/{PREFIX}.gene_positions.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a9869-3f33-4045-9710-901d46cd2961",
   "metadata": {},
   "source": [
    "We also exclude region with \"N\" using cutN from `SEQTK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35fc6243-385b-4355-85f2-9783826a38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!seqtk cutN -gp10000000 -n1 {REF_FA} > {INTDIR}/{PREFIX}.N_positions.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e4ba1-6bd2-456f-bf0a-0befc13a45ae",
   "metadata": {},
   "source": [
    "Finally, we extract gap regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "693c1803-9003-4d31-89eb-faa083cc8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- \"{GAP_URL}\" | sed 's/chr//' > {INTDIR}/{PREFIX}.gap_positions.bed #| sed 's/chr//'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe08b36-20f4-4d49-9abb-1de26c7e4396",
   "metadata": {},
   "source": [
    "We combine these 3 beds together, and sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65bc138e-2f3b-454c-b4fa-cd98f2e24a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {INTDIR}/{PREFIX}.*_positions.bed | sort -k1,1 -k2,2n | cut -f1-3 > {INTDIR}/{PREFIX}.to_exclude.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad899462-efef-461b-b515-4d0c142909e0",
   "metadata": {},
   "source": [
    "## Create and extract random sequences\n",
    "\n",
    "Next, to use `bedtools shuffle` to get random sequences, we need the chrom sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99b4109-ed79-4070-90b8-993375ce2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- \"{CHROM_URL}\" | sed 's/chr//' | grep -v \"_\\|M\\|Y\" > {INTDIR}/{PREFIX}.chrom.sizes # | sed 's/chr//' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea75ec3-704a-439b-8e84-ec61a2fdf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bedtools shuffle \\\n",
    "    -excl {INTDIR}/{PREFIX}.to_exclude.bed \\\n",
    "    -g {INTDIR}/{PREFIX}.chrom.sizes \\\n",
    "    -i {INTDIR}/{PREFIX}.sequences_length.bed > {INTDIR}/{PREFIX}.random_locations.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c75ffb4-1522-43ce-91a7-582d78470ff0",
   "metadata": {},
   "source": [
    "With the location of the new random sequences in the bed file, we can extract bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1562134-94b1-4c0a-84fa-ec96668e94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bedtools getfasta -fi {REF_FA} -bed {INTDIR}/{PREFIX}.random_locations.bed -name+ | tr a-z A-Z > {INTDIR}/{PREFIX}.random.species.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b11a9e-55c9-45c9-9696-20209569a0c2",
   "metadata": {},
   "source": [
    "## Merge both negative dataset files\n",
    "Finally, our false dataset will contained shuffled and random picked sequences. We merge each fasta with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d553719-de4b-4bf2-830a-a3e9748cbc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190041\n"
     ]
    }
   ],
   "source": [
    "!cat {INTDIR}/{PREFIX}.shuffled.species.{EXTREMITY}.fa {INTDIR}/{PREFIX}.random.species.fa > {INTDIR}/{PREFIX}.false.species.{EXTREMITY}.fa\n",
    "!grep -c \">\" {INTDIR}/{PREFIX}.false.species.{EXTREMITY}.fa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
